{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "337b878d",
   "metadata": {},
   "source": [
    "# Capstone Project: Model Comparison (GridSearchCV + Cross-Validation)\n",
    "**Goal:** Compare Logistic Regression vs. XGBoost for the primary capstone classification task (**30-day readmission**).  \n",
    "This notebook adds **cross-validation** and **GridSearchCV** to satisfy the rubric requirement for hyperparameter search.\n",
    "\n",
    "**Primary dataset:** UCI *Diabetes 130-US hospitals (1999â€“2008)* (processed file used in this repo).  \n",
    "**Target:** `readmitted_binary` (or `readmitted` if your processed file still uses that name).\n",
    "\n",
    "---\n",
    "## What this notebook produces\n",
    "- ROC curves (AUC)\n",
    "- Confusion matrices\n",
    "- Classification reports\n",
    "- A small model comparison table (CSV)\n",
    "- Saved figures into `../output/readmitted_binary/` (created if missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b86004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 1) Imports & Setup\n",
    "# =========================\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "OUT_DIR = os.path.join(\"..\", \"output\", \"readmitted_binary\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Output directory:\", os.path.abspath(OUT_DIR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb695f06",
   "metadata": {},
   "source": [
    "---\n",
    "## 2) Load Data\n",
    "This notebook expects your processed dataset to exist under:\n",
    "- `../Processed Data/processed_diabetes_data.csv` (preferred), or\n",
    "- `../Processed data/processed_diabetes_data.csv` (if folder name differs)\n",
    "\n",
    "If your processed file uses a different target column name, update `TARGET_CANDIDATES` below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6054205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 2) Load processed data\n",
    "# =========================\n",
    "candidate_paths = [\n",
    "    os.path.join(\"..\", \"Processed Data\", \"processed_diabetes_data.csv\"),\n",
    "    os.path.join(\"..\", \"Processed data\", \"processed_diabetes_data.csv\"),\n",
    "    os.path.join(\"..\", \"processed_diabetes_data.csv\"),\n",
    "]\n",
    "\n",
    "data_path = None\n",
    "for p in candidate_paths:\n",
    "    if os.path.exists(p):\n",
    "        data_path = p\n",
    "        break\n",
    "\n",
    "if data_path is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find processed_diabetes_data.csv. Checked:\\n\" + \"\\n\".join(candidate_paths)\n",
    "    )\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"Loaded:\", data_path)\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6a9994",
   "metadata": {},
   "source": [
    "---\n",
    "## 3) Define Target and Features\n",
    "We try common target names automatically. If your processed dataset uses a different name, add it to `TARGET_CANDIDATES`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 3) Define target + features\n",
    "# =========================\n",
    "TARGET_CANDIDATES = [\"readmitted_binary\", \"readmitted\", \"Readmitted\", \"target\"]\n",
    "\n",
    "target_col = None\n",
    "for c in TARGET_CANDIDATES:\n",
    "    if c in df.columns:\n",
    "        target_col = c\n",
    "        break\n",
    "\n",
    "if target_col is None:\n",
    "    raise ValueError(\n",
    "        \"Target column not found. Add your target name to TARGET_CANDIDATES. \"\n",
    "        f\"Available columns (first 30): {list(df.columns)[:30]}\"\n",
    "    )\n",
    "\n",
    "y = df[target_col].copy()\n",
    "\n",
    "# Ensure y is binary {0,1}\n",
    "if y.dtype == \"object\":\n",
    "    y = y.map({\"NO\": 0, \"<30\": 1, \">30\": 0}).fillna(y)\n",
    "\n",
    "y = pd.to_numeric(y, errors=\"coerce\")\n",
    "\n",
    "print(\"Target column:\", target_col)\n",
    "print(\"Unique target values:\", sorted(pd.Series(y).dropna().unique().tolist()))\n",
    "\n",
    "X = df.drop(columns=[target_col]).copy()\n",
    "X = X.dropna(axis=1, how=\"all\").fillna(0)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f4324",
   "metadata": {},
   "source": [
    "---\n",
    "## 4) Train/Test Split\n",
    "We use a **stratified** split to preserve class distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d404e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 4) Train / test split\n",
    "# =========================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \" Test:\", X_test.shape)\n",
    "print(\"Train positive rate:\", float(pd.Series(y_train).mean()))\n",
    "print(\"Test positive rate:\", float(pd.Series(y_test).mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3e44ae",
   "metadata": {},
   "source": [
    "---\n",
    "## 5) GridSearchCV + Cross-Validation (Rubric Requirement)\n",
    "To satisfy the rubric:\n",
    "- **Multiple models:** Logistic Regression + XGBoost  \n",
    "- **Cross-validation:** 5-fold `StratifiedKFold`  \n",
    "- **GridSearchCV:** hyperparameter tuning for each model  \n",
    "- **Metric:** ROC-AUC (robust for imbalanced classification and threshold-independent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca36d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 5) GridSearchCV with Cross-Validation\n",
    "# =========================\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "scoring = \"roc_auc\"\n",
    "\n",
    "# Logistic Regression pipeline (scale features)\n",
    "lr_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "lr_param_grid = {\n",
    "    \"clf__C\": [0.01, 0.1, 1.0, 10.0],\n",
    "    \"clf__penalty\": [\"l2\"],\n",
    "    \"clf__solver\": [\"lbfgs\"]\n",
    "}\n",
    "\n",
    "lr_grid = GridSearchCV(\n",
    "    estimator=lr_pipe,\n",
    "    param_grid=lr_param_grid,\n",
    "    scoring=scoring,\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# XGBoost classifier\n",
    "xgb = XGBClassifier(\n",
    "    random_state=RANDOM_STATE,\n",
    "    eval_metric=\"logloss\",\n",
    "    tree_method=\"hist\",\n",
    ")\n",
    "\n",
    "xgb_param_grid = {\n",
    "    \"n_estimators\": [200, 400],\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "    \"reg_lambda\": [1.0, 5.0],\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=xgb_param_grid,\n",
    "    scoring=scoring,\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Fitting Logistic Regression GridSearch...\")\n",
    "lr_grid.fit(X_train, y_train)\n",
    "print(\"Best LR params:\", lr_grid.best_params_)\n",
    "print(\"Best LR CV ROC-AUC:\", round(lr_grid.best_score_, 4))\n",
    "\n",
    "print(\"\\nFitting XGBoost GridSearch...\")\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "print(\"Best XGB params:\", xgb_grid.best_params_)\n",
    "print(\"Best XGB CV ROC-AUC:\", round(xgb_grid.best_score_, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3137b5",
   "metadata": {},
   "source": [
    "---\n",
    "## 6) Evaluate Best Models on the Held-Out Test Set\n",
    "We report ROC-AUC, confusion matrices, and classification reports.  \n",
    "Artifacts are saved into `../output/readmitted_binary/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3f87a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 6) Evaluation helpers\n",
    "# =========================\n",
    "def save_confusion_matrix(cm, title, filename):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, [\"0\", \"1\"])\n",
    "    plt.yticks(tick_marks, [\"0\", \"1\"])\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(int(cm[i, j]), \"d\"),\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def save_roc_curve(y_true, y_prob, title, filename):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    auc_val = roc_auc_score(y_true, y_prob)\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {auc_val:.4f}\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=150)\n",
    "    plt.close()\n",
    "    return auc_val\n",
    "\n",
    "def evaluate_and_save(name, model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_prob = model.decision_function(X_test)\n",
    "        y_prob = (y_prob - y_prob.min()) / (y_prob.max() - y_prob.min() + 1e-9)\n",
    "\n",
    "    auc_val = roc_auc_score(y_test, y_prob)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"\\n=== {name} (Test Set) ===\")\n",
    "    print(f\"ROC-AUC: {auc_val:.4f}\")\n",
    "    print(f\"Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_path = os.path.join(OUT_DIR, f\"confusion_matrix_{name}.png\")\n",
    "    save_confusion_matrix(cm, f\"Confusion Matrix - {name}\", cm_path)\n",
    "\n",
    "    roc_path = os.path.join(OUT_DIR, f\"roc_{name}.png\")\n",
    "    save_roc_curve(y_test, y_prob, f\"ROC Curve - {name}\", roc_path)\n",
    "\n",
    "    return {\"Model\": name, \"ROC_AUC\": auc_val, \"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1}\n",
    "\n",
    "best_lr = lr_grid.best_estimator_\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "\n",
    "results = []\n",
    "results.append(evaluate_and_save(\"LogReg_GridSearch\", best_lr, X_test, y_test))\n",
    "results.append(evaluate_and_save(\"XGB_GridSearch\", best_xgb, X_test, y_test))\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"ROC_AUC\", ascending=False)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4690784f",
   "metadata": {},
   "source": [
    "---\n",
    "## 7) Save Summary Table + Optional Feature Importance (XGBoost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b4bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 7) Save summary + feature importance\n",
    "# =========================\n",
    "summary_path = os.path.join(OUT_DIR, \"model_comparison_summary_gridsearch.csv\")\n",
    "results_df.to_csv(summary_path, index=False)\n",
    "print(\"Saved:\", os.path.abspath(summary_path))\n",
    "\n",
    "# Feature importance (Top 15) for XGBoost\n",
    "if hasattr(best_xgb, \"feature_importances_\"):\n",
    "    importances = pd.Series(best_xgb.feature_importances_, index=X.columns).sort_values(ascending=False).head(15)\n",
    "    fi_csv = os.path.join(OUT_DIR, \"feature_importance_XGB_GridSearch_top15.csv\")\n",
    "    importances.to_csv(fi_csv, header=[\"importance\"])\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    importances.sort_values().plot(kind=\"barh\")\n",
    "    plt.title(\"Top 15 Feature Importances - XGBoost (GridSearch Best Model)\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.tight_layout()\n",
    "    fi_png = os.path.join(OUT_DIR, \"feature_importance_XGB_GridSearch_top15.png\")\n",
    "    plt.savefig(fi_png, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Saved:\", os.path.abspath(fi_csv))\n",
    "    print(\"Saved:\", os.path.abspath(fi_png))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c798b53",
   "metadata": {},
   "source": [
    "---\n",
    "## 8) Interpretation (Non-Technical Takeaway)\n",
    "- **ROC-AUC** evaluates how well the model ranks high-risk patients across different thresholds (helpful when classes are imbalanced).\n",
    "- **GridSearchCV + 5-fold stratified CV** reduces the risk of overfitting to a single train/test split.\n",
    "- **XGBoost feature importance** supports interpretability and can guide discharge planning actions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
