# ðŸ“˜ Capstone_Prediction_Models.ipynb

# ðŸ”¹ Section 1: Import Libraries
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, classification_report, roc_curve, mean_absolute_error, mean_squared_error
from sklearn.linear_model import LogisticRegression, LinearRegression

# Install xgboost first
!pip install xgboost

# Then import xgboost
from xgboost import XGBClassifier, XGBRegressor
import os

# Ensure output directory exists
os.makedirs("output", exist_ok=True)

# ðŸ”¹ Section 2: Load Dataset
df = pd.read_csv("../Processed data/processed_diabetes_data.csv")
# Load the dataset
df = pd.read_csv(file_path)
print("Shape of dataset:", df.shape)
df.head()

# ðŸ”¹ Section 3: Utility Functions
def plot_roc(y_test, y_proba, model_name):
    try:
        fpr, tpr, _ = roc_curve(y_test, y_proba)
        plt.figure()
        plt.plot(fpr, tpr, label=f'ROC Curve ({model_name})')
        plt.plot([0, 1], [0, 1], linestyle='--')
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title(f'ROC Curve - {model_name}')
        plt.legend()
        
        # Make sure output directory exists
        os.makedirs("output", exist_ok=True)
        
        filename = f"output/roc_{model_name}.png"
        full_path = os.path.abspath(filename)
        plt.savefig(filename)
        plt.close()
        
        print(f"ROC curve saved successfully at: {full_path}")
        return True
    except Exception as e:
        print(f"Error creating ROC plot: {str(e)}")
        return False

# Let's create a simple test plot to verify the function works
import numpy as np

# Create some dummy data
np.random.seed(42)
dummy_y_true = np.random.randint(0, 2, 100)  # Binary labels
dummy_y_score = np.random.random(100)  # Random probabilities

# Call the function with dummy data
success = plot_roc(dummy_y_true, dummy_y_score, "test_model")

# Check if the file was created
if success:
    print(f"Files in output directory after creating plot: {os.listdir('output')}")


# ðŸ”¹ Section 4: Prediction Tasks
### Define Tasks
classification_targets = ["readmitted_binary", "A1Cresult", "insulin"]
regression_targets = ["number_inpatient", "time_in_hospital"]

### Define Features (exclude targets and identifier columns)
targets = classification_targets + regression_targets
X = df.drop(columns=targets + ['encounter_id', 'patient_nbr'], errors='ignore')


# ðŸ”¹ Section 5: Classification Models
for target in classification_targets:
    print(f"\nðŸŽ¯ Classification Target: {target}")
    y = df[target]
    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)

    # Logistic Regression
    lr = LogisticRegression(max_iter=1000)
    lr.fit(X_train, y_train)
    y_pred_lr = lr.predict(X_test)
    y_proba_lr = lr.predict_proba(X_test)[:, 1] if len(np.unique(y)) == 2 else None
    acc_lr = accuracy_score(y_test, y_pred_lr)
    print(f"Logistic Regression Accuracy: {acc_lr:.4f}")

    # ROC Curve
    if y_proba_lr is not None:
        plot_roc(y_test, y_proba_lr, f"{target}_LogReg")

    # XGBoost Classifier
    xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
    xgb_clf.fit(X_train, y_train)
    y_pred_xgb = xgb_clf.predict(X_test)
    y_proba_xgb = xgb_clf.predict_proba(X_test)[:, 1] if len(np.unique(y)) == 2 else None
    acc_xgb = accuracy_score(y_test, y_pred_xgb)
    print(f"XGBoost Accuracy: {acc_xgb:.4f}")

    # Classification Report
    report = classification_report(y_test, y_pred_xgb, output_dict=True)
    report_df = pd.DataFrame(report).transpose()
    report_df.to_csv(f"output/classification_report_{target}.csv")

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred_xgb)
    sns.heatmap(cm, annot=True, fmt='d')
    plt.title(f"Confusion Matrix - {target}")
    plt.savefig(f"output/confusion_matrix_{target}.png")
    plt.close()

    # ROC Curve
    if y_proba_xgb is not None:
        plot_roc(y_test, y_proba_xgb, f"{target}_XGB")

    # Feature Importance
    plot_feature_importance(xgb_clf, X, f"{target}_XGB")


# ðŸ”¹ Section 6: Regression Models
for target in regression_targets:
    print(f"\nðŸŽ¯ Regression Target: {target}")
    y = df[target]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    # Linear Regression
    lr = LinearRegression()
    lr.fit(X_train, y_train)
    y_pred_lr = lr.predict(X_test)
    print("Linear Regression MAE:", mean_absolute_error(y_test, y_pred_lr))
    print("Linear Regression RMSE:", mean_squared_error(y_test, y_pred_lr, squared=False))

    # XGBoost Regressor
    xgb_reg = XGBRegressor()
    xgb_reg.fit(X_train, y_train)
    y_pred_xgb = xgb_reg.predict(X_test)

    # Save predictions
    out_df = pd.DataFrame({"actual": y_test, "predicted": y_pred_xgb})
    out_df.to_csv(f"output/predictions_{target}.csv", index=False)

    # Evaluation
    mae = mean_absolute_error(y_test, y_pred_xgb)
    rmse = mean_squared_error(y_test, y_pred_xgb, squared=False)
    print("XGBoost MAE:", mae)
    print("XGBoost RMSE:", rmse)

    # Feature Importance
    plot_feature_importance(xgb_reg, X, f"{target}_XGB")


# ðŸ”¹ Section 7: Completion Notice
print("\nâœ… All models completed. Outputs saved in /output folder.")
